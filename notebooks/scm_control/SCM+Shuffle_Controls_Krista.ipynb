{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # for aesthetic\n",
    "\n",
    "import neuraltda.topology2 as tp2\n",
    "import neuraltda.spectralAnalysis as sa\n",
    "import neuraltda.simpComp as sc\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import h5py as h5\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rejection_sampling(command, seed=0):\n",
    "    # Call sampler with subprocess\n",
    "    proc = sp.run(command, stdout=sp.PIPE)\n",
    "    # Read output as a facet list \n",
    "    facet_list = []\n",
    "    for line in proc.stdout.decode().split(\"\\n\")[1:-1]:\n",
    "        if line.find(\"#\") == 0:\n",
    "            yield facet_list\n",
    "            facet_list = []\n",
    "        else:\n",
    "            facet_list.append([int(x) for x in line.strip().split()])\n",
    "    yield facet_list\n",
    "    \n",
    "def prepare_scm_initial_condition(binmat, **kwargs):\n",
    "    \n",
    "    facets = sc.binarytomaxsimplex(binmat, rDup=True, **kwargs)\n",
    "    with tempfile.NamedTemporaryFile(mode='w+t', delete=False) as f: \n",
    "        fname = f.name\n",
    "        for facet in facets:\n",
    "            fstr = str(facet)\n",
    "            fstr = fstr.replace('(', '')\n",
    "            fstr = fstr.replace(')', '')\n",
    "            fstr = fstr.replace(',', '')\n",
    "            f.write(fstr+'\\n')\n",
    "    return fname\n",
    "\n",
    "def prepare_scm_command(facet_file, nsamps):\n",
    "    \n",
    "    command = ['/home/brad/bin/mcmc_sampler', facet_file, '-t', str(nsamps)]\n",
    "    return command\n",
    "\n",
    "def extract_population_tensor(binned_data_file, stim, shuffle=False, clusters=None):\n",
    "    print('Extracting Population Activity Tensor...')\n",
    "    with h5.File(binned_data_file, 'r') as bdf:\n",
    "        binned_clusters = np.array(bdf[stim]['clusters'])\n",
    "        poptens = np.array(bdf[stim]['pop_tens'])\n",
    "        print('Stim: {}, Clusters:{}'.format(stim, str(clusters)))\n",
    "        try:\n",
    "            if clusters is not None:\n",
    "                poptens = poptens[np.in1d(binned_clusters, clusters), :, :]\n",
    "                print(\"Selecting Clusters: poptens:\" + str(np.shape(poptens)))\n",
    "            (ncell, nwin, ntrial) = np.shape(poptens)\n",
    "        except (ValueError, IndexError):\n",
    "            print('Population Tensor Error')\n",
    "            return []\n",
    "        if shuffle:\n",
    "            poptens = tp2.build_shuffled_data_tensor(poptens, 1)\n",
    "            poptens = poptens[:, :, :, 0]\n",
    "        if  nwin == 0:\n",
    "            return []\n",
    "    return poptens\n",
    "            \n",
    "def compute_trial_final_bettis(poptens, thresh, trial):\n",
    "    popmat = poptens[:, :, trial]\n",
    "    nclus = num_cells(poptens)\n",
    "    popmat_binary = sc.binnedtobinary(popmat, thresh)\n",
    "    bettis = tp2.calc_bettis(popmat, np.arange(nclus), '/home/brad/betti_pfile.txt', thresh)\n",
    "    final_bettis = bettis[-1][1]\n",
    "    return final_bettis\n",
    "\n",
    "def num_trials(poptens):\n",
    "    (ncells, nwin, ntrials) = np.shape(poptens)\n",
    "    return ntrials\n",
    "\n",
    "def num_win(poptens):\n",
    "    (ncells, nwin, ntrials) = np.shape(poptens)\n",
    "    return nwin\n",
    "\n",
    "def num_cells(poptens):\n",
    "    (ncells, nwin, ntrials) = np.shape(poptens)\n",
    "    return ncells\n",
    "    \n",
    "    \n",
    "def calc_scm_betti_distribution(poptens, thresh, trial, nsamples):\n",
    "    popmat = poptens[:, :, trial]\n",
    "    popmat_bin = sc.binnedtobinary(popmat, thresh)\n",
    "    fname = prepare_scm_initial_condition(popmat_bin)\n",
    "    cmd = prepare_scm_command(fname, nsamples)\n",
    "    samples = rejection_sampling(cmd)\n",
    "    sample_bettis = []\n",
    "    for sample in samples:\n",
    "        bettis=[]\n",
    "        cgs = [[1, x] for x in sample]\n",
    "        tp2.build_perseus_input(cgs, '/home/brad/betti_pfile.txt')\n",
    "        betti_file = tp2.run_perseus('/home/brad/betti_pfile.txt')\n",
    "        try:\n",
    "            with open(betti_file, 'r') as bf:\n",
    "                for bf_line in bf:\n",
    "                    if len(bf_line) < 2:\n",
    "                        continue\n",
    "                    betti_data = bf_line.split()\n",
    "                    filtration_time = int(betti_data[0])\n",
    "                    betti_numbers = map(int, betti_data[1:])\n",
    "                    bettis.append([filtration_time, betti_numbers])\n",
    "        except:\n",
    "            bettis.append([-1, [-1]])\n",
    "        sample_bettis.append(bettis)\n",
    "    return np.array(sample_bettis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'neuraltda.topology2' from '/home/brad/code/NeuralTDA/neuraltda/topology2.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(tp2.events)\n",
    "reload(tp2.core)\n",
    "reload(tp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/logging/__init__.py\", line 994, in emit\n",
      "    stream.write(msg)\n",
      "AttributeError: 'int' object has no attribute 'write'\n",
      "Call stack:\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/brad/.conda/envs/neuraltda-3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-8bc9d53aa4bd>\", line 6, in <module>\n",
      "    bfdict = tp2.dag_bin(block_path, winsize, segment_info, cluster_group=['Good', 'MUA'], dt_overlap=pover*winsize, comment='fulltrial')\n",
      "  File \"/home/brad/code/NeuralTDA/neuraltda/topology2.py\", line 860, in dag_bin\n",
      "    fs, winsize, segment_info, **kwargs)\n",
      "  File \"/home/brad/code/NeuralTDA/neuraltda/topology2.py\", line 926, in do_dag_bin_lazy\n",
      "    setup_logging('Dag Bin')\n",
      "  File \"/home/brad/code/NeuralTDA/neuraltda/topology2.py\", line 76, in setup_logging\n",
      "    logger.info('Starting {}.'.format(func_name))\n",
      "Message: 'Starting Dag Bin.'\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "winsize = 10.0\n",
    "segment_info = [0, 0]\n",
    "pover = 0.5\n",
    "block_path = '/home/brad/krista/B1075/P01S03/'\n",
    "# Bin and compute SCG\n",
    "bfdict = tp2.dag_bin(block_path, winsize, segment_info, cluster_group=['Good', 'MUA'], dt_overlap=pover*winsize, comment='fulltrial')\n",
    "binned_data_file = glob.glob(os.path.join(bfdict['raw'], '*.binned'))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: A_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: A_40k, Clusters:None\n",
      "B_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: B_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: B_40k, Clusters:None\n",
      "C_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: C_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: C_40k, Clusters:None\n",
      "D_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: D_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: D_40k, Clusters:None\n",
      "E_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: E_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: E_40k, Clusters:None\n",
      "F_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: F_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: F_40k, Clusters:None\n",
      "G_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: G_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: G_40k, Clusters:None\n",
      "H_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: H_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: H_40k, Clusters:None\n",
      "I_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: I_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: I_40k, Clusters:None\n",
      "J_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: J_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: J_40k, Clusters:None\n",
      "K_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: K_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: K_40k, Clusters:None\n",
      "L_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: L_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: L_40k, Clusters:None\n",
      "M_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: M_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: M_40k, Clusters:None\n",
      "N_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: N_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: N_40k, Clusters:None\n",
      "O_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: O_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: O_40k, Clusters:None\n",
      "P_40k\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: P_40k, Clusters:None\n",
      "Extracting Population Activity Tensor...\n",
      "Stim: P_40k, Clusters:None\n"
     ]
    }
   ],
   "source": [
    "thresh = 13\n",
    "nsamples = 10\n",
    "\n",
    "with h5.File(binned_data_file, 'r') as bdf:\n",
    "    stims = bdf.keys()\n",
    "    for stim in stims:\n",
    "        print(stim)\n",
    "        stim_poptens = extract_population_tensor(binned_data_file, stim)\n",
    "        stim_poptens_shuffled = extract_population_tensor(binned_data_file, stim, shuffle=True)\n",
    "        ntrials = num_trials(stim_poptens)\n",
    "        for trial in range(ntrials):\n",
    "            \n",
    "            stim_bettis = compute_trial_final_bettis(stim_poptens, thresh, trial)\n",
    "            \n",
    "            stim_shuffled_bettis = compute_trial_final_bettis(stim_poptens_shuffled, thresh, trial)\n",
    "            \n",
    "            scm_bettis = calc_scm_betti_distribution(stim_poptens, thresh, trial, nsamples)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stim_bettis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list([[1, <map object at 0x7f58658a75c0>], [2, <map object at 0x7f58658a7358>], [3, <map object at 0x7f58658a7198>], [4, <map object at 0x7f58658a7f98>], [5, <map object at 0x7f58658a7f28>], [6, <map object at 0x7f58658a7e80>], [7, <map object at 0x7f58658a76a0>], [8, <map object at 0x7f58658a75f8>], [10, <map object at 0x7f58658a7860>]]),\n",
       "       list([[1, <map object at 0x7f58658a72b0>], [2, <map object at 0x7f58658a7eb8>], [3, <map object at 0x7f58658a7278>], [4, <map object at 0x7f58658a7a20>], [5, <map object at 0x7f58658a7da0>], [6, <map object at 0x7f58658a7ef0>], [7, <map object at 0x7f58658a7400>], [8, <map object at 0x7f58658ac1d0>], [9, <map object at 0x7f58658acc88>]]),\n",
       "       list([[1, <map object at 0x7f58658a7080>], [2, <map object at 0x7f58658a7fd0>], [3, <map object at 0x7f586593ea58>], [4, <map object at 0x7f586593ed68>], [5, <map object at 0x7f586593ee10>], [6, <map object at 0x7f586593e828>], [7, <map object at 0x7f586593e2e8>], [8, <map object at 0x7f586593e550>], [9, <map object at 0x7f586593e470>]]),\n",
       "       list([[1, <map object at 0x7f586593e710>], [2, <map object at 0x7f586593e4e0>], [3, <map object at 0x7f586593e518>], [4, <map object at 0x7f586593e5f8>], [5, <map object at 0x7f586593ecf8>], [6, <map object at 0x7f586593e240>], [7, <map object at 0x7f586593e1d0>], [9, <map object at 0x7f586593e940>], [10, <map object at 0x7f586593e7b8>]]),\n",
       "       list([[1, <map object at 0x7f586593ecc0>], [2, <map object at 0x7f586593e400>], [3, <map object at 0x7f586593e6a0>], [4, <map object at 0x7f586593ec18>], [5, <map object at 0x7f586593ef98>], [6, <map object at 0x7f58658b5a58>], [7, <map object at 0x7f58658b5e80>], [9, <map object at 0x7f58658b5630>], [10, <map object at 0x7f58658b5ac8>]]),\n",
       "       list([[1, <map object at 0x7f586593e320>], [2, <map object at 0x7f58658b5550>], [3, <map object at 0x7f58658b5e48>], [4, <map object at 0x7f58658b5dd8>], [5, <map object at 0x7f58658b5a90>], [6, <map object at 0x7f58658b5438>], [7, <map object at 0x7f58658b5048>]]),\n",
       "       list([[1, <map object at 0x7f58658b5208>], [2, <map object at 0x7f58658b5978>], [3, <map object at 0x7f58658b5358>], [4, <map object at 0x7f58658b5c18>], [5, <map object at 0x7f58658b5d30>], [6, <map object at 0x7f58658b5400>], [7, <map object at 0x7f58658b5b00>]]),\n",
       "       list([[1, <map object at 0x7f58658b5d68>], [2, <map object at 0x7f58658b52b0>], [3, <map object at 0x7f58658a9f60>], [4, <map object at 0x7f58658a9240>], [5, <map object at 0x7f58658a9be0>], [6, <map object at 0x7f58658a9278>], [7, <map object at 0x7f58658a9940>]]),\n",
       "       list([[1, <map object at 0x7f5868fac898>], [2, <map object at 0x7f58658a9e80>], [3, <map object at 0x7f58658a9da0>], [4, <map object at 0x7f58658a9978>], [5, <map object at 0x7f58658a9dd8>], [6, <map object at 0x7f58658a9780>], [7, <map object at 0x7f58658a9828>]]),\n",
       "       list([[1, <map object at 0x7f58658aa940>], [2, <map object at 0x7f58658aa6d8>], [3, <map object at 0x7f58658aa320>], [4, <map object at 0x7f58658aae80>], [5, <map object at 0x7f58658aa780>], [6, <map object at 0x7f58658aaa90>], [7, <map object at 0x7f58658aa5f8>]])], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm_bettis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
